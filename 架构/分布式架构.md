# 分布式架构

## 1 分布式系统知识体系大图

### <img src="/Users/jiangxiaolong/自学整理/架构/image/分布式架构图.jpeg" alt="分布式架构图" style="zoom:50%;" />

## 2 SOA 到 MSA的进化

### 2.1 SOA 面向服务架构

```
由于业务发展到一定的程度后，需要对服务进行解耦，进而把一个单一的大系统按逻辑拆分成不同的子系统，通过服务接口来通讯。
面向服务的设计模式，最终需要总线集成服务，而且大部分时候还需要共享数据库，出现单点故障是会导致总线层面的故障，
更进一步可能会把数据库拖垮，所以才有了更加独立的设计方案的出现--->微服务架构
```

<img src="/Users/jiangxiaolong/自学整理/架构/image/面向服务的架构图.jpeg" alt="面向服务的架构图" style="zoom:50%;" />

### 2.2 MSA 微服务架构

```
微服务是真正意义上的独立服务，从服务入口到数据持久层，逻辑上都是独立隔离的，无需服务总线来接入，
但同事也增加了整个分布式系统的搭建个管理制度，需要对服务进行编排和管理，所以伴随着为服务的兴起，
微服务生态的技术栈也需要无缝的接入，才能支撑起微服务的治理理念。
```

<img src="/Users/jiangxiaolong/自学整理/架构/image/微服务的架构图.jpeg" alt="微服务的架构图" style="zoom:50%;" />

## 3  节点与网络

### 3.1  节点

```
传统的节点也就是一台单机的物理机，所有的服务都肉进去，包括服务和数据库。
伴随着虚拟化发展，单台物理机往往可以分成多太的虚拟机，实现资源利用最大化，节点的概念也就变成单台虚拟机上面的服务。
近几年容器技术逐渐成熟后，服务已经彻底容器化， 也就是节点只是轻量级的容器服务。
总体来说，节点就是能提供单位服务的逻辑计算资源的集合。
```

### 3.2  网络

```
分布式架构的根基就是网络，不管是局域网还是公网，没有网络就无法把计算机联合在一起工作，但是网络也带来了一系列的问题。
网络消息的传播有先有后，消息丢失和延迟是经常发生的事情。三种网络的工作模式：
1. 同步网络：
 	  节点同步执行
 	  消息延迟有限
 	  高效全局锁

2. 半同步网络：
		锁范围放宽

3. 异步网络：
	节点独立执行
	消息延迟无上限
	无全局锁
	部分算法不可行
	
常用网络传输层的两大协议的特点：
  TCP协议：
  	tcp协议传输的可靠性：
  		校验和
  		序列号
  		确认应答
  		超时重发
  		连接管理
  		流量控制
  		拥塞控制
  	tcp解决重复和乱序的问题
  	提高性能:
  		滑动窗口
  		快速重传
  		延迟应答
  		捎带应答
  UDP协议：
  	常亮数据流
  	丢包不致命
```

## 4. 时间与顺序

### 4.1 时间

```
慢速物理时空中，时间独自在流淌着，对于串行的事物来说，很简单的就是跟着时间的脚步就可以，先来后到的发生。
而后我们发明了时钟来刻画以往的时间点，时钟让这个世界井然有序。但是对分布式世界来说，跟时间打交道着实是一件痛苦的事情。

分布式世界里面，我们要协调不同的节点之间的先来后到的关系， 不同节点本身承认的时间又各执己见，于是我们创造了网络时间协议（NTP）
试图来解决不同节点之间的标准时间，但是NTP本身表现的并不尽人意，所以我们又构造出了“逻辑时钟”，最后改进为“向量时钟”：
```

#### 4.1.1 网络时间协议：NTP的一些缺点

```
 节点时间不同步
 硬件时钟漂移
 硬件休眠
 线程可能休眠
 操作系统可能休眠 
```

<img src="/Users/jiangxiaolong/自学整理/架构/image/NTP.png" alt="NTP" style="zoom:50%;" />

#### 4.1.2 逻辑时钟

```
定义事件先来后到
t' = max(t, t_msg + 1)
```

<img src="/Users/jiangxiaolong/自学整理/架构/image/逻辑时钟.png" alt="逻辑时钟" style="zoom:50%;" />

#### 4.1.3 向量时钟

```
t_i' = max(t_i, t_msg_i)
```

#### 4.1.4 原子时钟

### 4.2 顺序

```
有了衡量时间的工具，解决顺序问题自然就是水到渠成了。
因为整个分布式的理论基础及时如何协商不同节点的一致性问题，而顺序则是一致性问题的基本概念。
所以前文我们才需要花时间街道衡量时间的刻度和工具。
```

### 5 一致性理论

#### 5.1.1 强一致性ACID

```
单机环境下对于我们传统关系型数据库有严苛的要求，由于存在网络的延迟和消息，ACID便是保证事物的原则。
Atomicity: 原子性 一个事物中所有的操作，要么全部完成，要么全部不完成，不会结束在中间某个环节；
Consistency: 一致性 在事物开始之前和结束以后，数据库的完整性没有破坏；
Isolation: 隔离性 数据库允许多个并发事物同时对数据进行读写修改的能力，隔离性可以防止多个事物并发执行时由于交叉执行而导致数据的不一致
Durabilt: 持久性 事物处理结束后，对数据的修改就是永久的，便是系统也故障也不会丢失。
```

#### 5.1.2 分布式一致性 CAP

```
分布式环境下，我们无法保证网络的正常连接个信息的传送，于是发展出了CAP/FLP/DLS 这三个重要的理论：
CAP: 分布式计算机不可能同时确保一致性（Consistency）、可用性（Availablity）和分区容忍性（Partition）
FLP:在异步环境中，如果节点的网络延迟没有上限， 只要有一个恶意的节点存在，就没有算法能在有限的时间内达成共识
DLS:
    在一个部分同步网络的模型(也就是说：网络延时有界限但是我们不知道在哪里)下运行的协议可以容忍1/3任意错误。
    在一个异步模型的确定性的协议(没有网络上限)不能容错(不过这个论文没有提起随机化算法可以容忍1/3的错误)
    同步模型中的协议(网络延时可以保证小于已知D时间)，可以令人吃惊的达到100%容错，虽然对1/2的节点出错可以发生的情况有所限制
```

#### 5.1.3 弱一致性BASE

```
多数情况下，其实我们也并非要求强一致性，部分业务可以容忍一定程度的延迟一致，所以为了兼顾效率、发展出来了最综一致性原则BASE。
BASE是指基本可用(Basically Available)、软状态(Soft State)、最終一致性(Eventual Consistency)
 基本可用：指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用
 软状态：	软状态是指允许存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本     				  的延时就是软转态的提现。
 最终一致性：是指系统中的所有数据副本经过一定时间后，最综能够达到一致的状态。弱状态性和强一致性相反，最综一致性的一种特殊情况。
```

### 6. 一致性算法

``` 
分布式架构的核心就在于一致性的实现和妥协，那么如何设计一套算法来保证不同节点之间的通信和数据达到无限趋向一致性，就非常重要了。
保证不同节点在充满不确定性网络环境下能达成相同副本的一致性是非常困难得，业界对该课题也做了大量的研究。

1. 首先我们要了解一致性的大前提原则(CALM)：
	CALM原则的全程是Consistency and Logical Monotonicity,主要描述的是分布式中单调逻辑与一致性的关系
		在分布式中，单调的逻辑都能保证”最终一致性“，这个过程中不需要依赖中心的调度；
		任意分布式系统，如果所有的非单调逻辑都有中心节点调度，那么这个分布式稀系统就可以实现最终的”一致性“
		
2. 然后我们再关注分布式系统的数据结构CRDT(Confilct-Free Replicated Data Types)
		我们了解到分布式一些规律之后，就要着手考虑如何实现解决方案，一致性算法的前提是数据结构，或者说一切算法的根基就是数据结构，设计良好的数据结构加上精妙的算法可以高效的解决现实的问题。经过前人不断的参考
    基于状态（state-based）：即将各个节点之间的CEDT数据直接进行合并，所有节点都能最终合并到同一个状态，数据合并的顺序不会影响到最终的结果
    基于操作（operation-based）：将每一次对数据的操作通知给其他的节点。只要节点知道了对数据的所有操作，就能合并到同一状态。
    
3. 了解数据结构后，我们需要来关注一下分布式系统的一些重要的协议HATs(Highly Available Transactions), ZAB(Zookeeper Atomic Broadcast) 参考《高可用事物》,《ZAB协议分析》

4.最后要学习的是业界主流的一致性算法： 
   一致性算法的是分布式系统最核心的本质内容，这部分的发展也会影响架构的革新，不同的场景的应用也催生出不同的算法
   Paxos:《优雅的Paxos算法》
   Paft:《Paft一致性算法》
   Gossip:《Gossip Visualization》
```

### 7. 设计模式(提高系统性能)

#### 7.1 可用性

```
可用性是系统运行和工作的时间比例，通常一正常运行时间的百分比来衡量。他可能承受系统错误、基础架构问题、恶意攻击和负载均衡的影响。
分布式系统通常为用户提供服务级别协议（SLA)， 因此应用程序必须设计为最大化的可用性。。
	健康检查：系统实现链路功能检查，外部工具定期通过公开端点访问系统
	负载均衡： 使用队列起到削峰作用， 作为请求和服务之间的缓冲区，以平滑间歇性的重负载
	节流：限制应用级别、租户或整个服务所消耗资源的范围
```

#### 7.2 数据管理

```
数据管理是分布式系统的关键要素，并影响打多数质量的属性。由于性能，可扩展性或者可用性等原因，数据通常拖管在不同位置和多个服务器上，这肯可能带来一系列的挑战。例如，必须维护数据一致性，并且通常需要跨不同位置同步数据。

    缓存：根据需要将数据从数据库存储层加载到缓存
    CQRS(Command QUery Responsibility Segregation): 命令查询职责分离
    事件溯源：仅使用追加方式记录域中完整的系列事件
    索引表：在经常查询引用的字段上创建索引
    物化视图：生成一个或多个数据预填充视图
    拆分：将数据拆分为水平的分区或分片
```

#### 7.3 设计与实现

```
良好的设计包括诸如组件设计和部署的一致性、简化管理和开发的可维护性、以及允许组件和子系统用于其他应用程序和其他方案的可重用性等因素。。在设计和实施阶段做出的决策对分布式系统和服务质量和总体拥有成本产生巨大影响。
	代理：反向代理
	适配器：在现代应用程序和遗留系统之间实现适配器层
	前后端分离：后端服务提供接口供前端应用程序调动
	计算资源整合：将多个相关任务或操作和并到一个计算单元中
	配置分离：将配置信息从应用程序部署包中移出到配置中心
	网管聚合：使用网管将多个单独服务的请求聚合到一个请求中
	网管卸载：将共享或专用服务功能卸载到网关代理
	网管路由：使用单个端点将请求路由到多个服务
  领导人选举：通过选择一个实例作为负责管理其他实例管理员，协调分布式系统的运行
  通道和过滤出器：将复杂的任何分解为一系列可以重复使用的单独组件
  边车：将应用的监控组件部署到单独的进程或容器中，已提供隔离和封装
  静态内容托管：将静态内容部署到CDN,加速访问效率
```

#### 7.4 消息

```
分布式系统需要一个连接组建和消息传递组件，理想情况是以松散耦合的方式，以便最大限度地提高可伸缩性。
异步消息传递被广泛使用，并提供许多好处，但也带来了诸如消息排列、幂等性等挑战。
	竞争消费者：多线程并发消费
	优先级队列：消费队列份优先级，优先级高的先被消费
```

#### 7.5 弹性

```
弹性是指系统能够优雅地处理故障并从故障中恢复。分布式系统通常是多租户，使用共享平台服务、竞争资源和带宽，通过internet进行通信，以及在商用硬件上运行，意味着出现瞬态和更永久性故障的可能性增加。为了保持弹性，必须快速有效地检测故障并进行恢复。
	隔离：将应用程序的元素隔离到池中，以便在其中一个失败时，其他元素将继续运行
	断路器：处理连接到远程服务或资源时可能需要不同时间修复的故障
	补偿交易：撤销一系列步骤执行的工作，这些步骤共同定义一致的操作
	健康检查：系统实现全链路功能检查，外部工具定期通过公开端点访问系统
	重试：通过透明地重试先前失败的操作，使用应用程序在尝试连接到服务或网络资源时处理预期临时故障
```

#### 7.6 安全

```
安全性是系统能够防止在设计使用之外的恶意或意外的行为，并防止泄露或者丢失信息。分布式系统在受信任的本地边界之外的internet 上运行，通常向公众公布，并且可以为不受信任的用户提供服务。必须以保护应用程序免受恶意攻击，限制仅允许对已批准用户的访问，并保护敏感数据。
	联合身份：将身份验证委派给外部身份提供商
	看门人：通过使用专用主机实例来保护应用程序和服务，该实例充当客户端与应用程序或服务之间的代理，验证和清理请求，并在他们之间传递请求和					数据。
	代理钥匙：使用为客户端提供对特定资源或者或服务的受限直接访问的令牌或秘钥
```

### 8 工程应用

#### 8.1 资源调度

```
我们一切的软件系统都是构建在硬件服务器的基础上。从最开始的物理机直接部署软件系统，到虚拟机的应用，最后到了资源上云容器化，
硬件资源的使用也开始了集约化的管理。
过去软件系统随着用户量的增加需要增加机器资源的话，传统的方式几乎是找运维申请机器，然后部署好软间服务接入集群，整个过程依赖的是运维人员
的人肉经验，效率低而且容易出错。微服务分布式则无需人肉增家机器，在容器化技术的支撑下，我们只需要申请云资源，然后执行容器脚本即可。
	
	应用扩容：用户激增需要付服务进行扩展，包括自动化扩容，峰值过后的自动缩容
	机器下线：对于过时应用，进行应用下线，云平台收回容器宿主资源
	机器置换：对于故障机器，可供置换机器宿主资源，服务自动启动，无缝切换
```

#### 8.2 网络管理

```
有了计算资源后，另外最最要的就是网络资源了。在现有的云背景下，我们几乎不会直接接触到物理的带宽资源，而是直接由云平台统一管理带宽资源。我们需要的是对网络资源的最大化应用和有效的管理。
	
	域名申请：应用申请配套域名资源的申请，多套域名映射规则的规范。
	域名变更：域名变更统一平台管理
	负载管理：多机应用的访问策略设定
	安全外联：基础访问鉴权，拦截非法请求
	统一接入：提供统一接入的权限申请平台，提供统一的登入管理
```

#### 8.3 故障快照

```
在系统故障的时候我们第一要务是系统恢复，同时保留案发现场也是非常重要的，资源调度平台则需要有统一的机制保存好故障现场。
   现场保留：内存分布，线程数等资源现象的保存。如 javaDump构造接入
   调试接入：采用字节码技术无需入侵业务代码，可以提供生产环境现场日志大打点调试
```

### 9.流量调度

#### 9.1 负载均衡

```
负载均衡是我们对服务如何消化流量的通用设计。通常分为物理层的底层协议分流的硬负载均衡和软件层的软负载均衡。
负载均衡解决方案已经是业界成熟的方案，我们通常会针对业务在不同环境进行优化，通常有如下的负载均衡解决方案
   交换机
   F5
   LVS/ALI_LVS
   Nginx/Tengine
   VIPServer/ConfigServer
```

#### 9.2 网关设计

```
负载均衡首当其冲的就是网管，因为中心化集群流量最先打到的地方就是网关，如果网关扛不住压力的话，那么整个系统将不可用。
	高性能：网关设计第一需要考虑的就是高性能的流量转发，网关单节点通常能到达上百万的并发流量
	分布式：处于流量压力分担和灾备考虑，网关设计同样需要分布式
	业务筛选：网关设计简单的规则，排除掉大部分的恶意流量
```

#### 9.3 流量管理

```
请求校验：请求鉴权可以吧多少非法的请求拦截，清洗
数据缓存：多数去转态的请求存在数据热点，所以采用CDN可以把相当大的一部分的流量消费掉
```

#### 9.4 流量控制

```
剩下真实的流量我们采用不同的算法来分流请求
  流量分配：	
  		计数器
  		队列
  		漏斗
  		令牌桶
  		动态流控
  流量限制在流量激增的时候，通常我们需要有限流措施来防止系统出现雪崩，那么就需要预估系统的流量上限，然后设定好上限数，单流量增加一定阈值后，多出来的流量则不会进入系统，通过牺牲部分流量来保全系统的可用性。
  限流策略
  QPS粒度
  线程数粒度
  RT阈值
  限流工具--Sentinel
```

### 10 服务调度

```
流量做好了调度管理后，剩下的就是服务自身的健壮性了。分布式系统服务出现故障是常有的事情，甚至我们需要把故障本身当做是分布式服务的一部分
```

#### 10.1 注册中心

```
网关是流量的集散地，而注册中心则是服务的根据地。
  状态类型：定义好服务的状态，通过注册中心就可以检测服务是否可用
  生命周期：应用服务不同的状态组成了应用的生命周期
```

#### 10.2 版本管理

```
集群版本：集群不用应用有自身对应的版本号，由不同服务组成的集群也需要定义大的版本号
版本回滚：在部署异常的时候可以根据大的集群版本进行回滚管理
```

#### 10.3  服务编排

```
通过消息的交互序列老控制各个部分资源的交互。
参与交互的资源都是对等的，没有集中的控制。微服务环境下的服务众多我们需要有一个总的协调来协议服务之间的依赖，调用关系，k8s则是我们不二的选择。
      k8s
      Spring Cloud
        HSF 
        ZK + DUbbo
```

### 10. 参考文献

https://developer.aliyun.com/article/721007